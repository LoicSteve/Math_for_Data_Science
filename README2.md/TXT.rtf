{\rtf1\ansi\ansicpg1252\cocoartf2639
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Arial-BoldMT;\f1\froman\fcharset0 Times-Roman;\f2\fswiss\fcharset0 ArialMT;
\f3\fmodern\fcharset0 Courier;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;\red16\green60\blue192;}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c0;\cssrgb\c6667\c33333\c80000;}
{\*\listtable{\list\listtemplateid1\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid1\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid1}
{\list\listtemplateid2\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid101\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid2}
{\list\listtemplateid3\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid201\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid3}
{\list\listtemplateid4\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid301\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid4}
{\list\listtemplateid5\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat2\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid401\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid5}
{\list\listtemplateid6\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid501\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid6}
{\list\listtemplateid7\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat3\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid601\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid7}
{\list\listtemplateid8\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid701\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid8}
{\list\listtemplateid9\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat4\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid801\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid9}
{\list\listtemplateid10\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid901\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid10}
{\list\listtemplateid11\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid1001\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid11}
{\list\listtemplateid12\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid1101\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid12}
{\list\listtemplateid13\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid1201\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid13}
{\list\listtemplateid14\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid1301\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid14}
{\list\listtemplateid15\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid1401\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid15}
{\list\listtemplateid16\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid1501\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid16}
{\list\listtemplateid17\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid1601\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid17}
{\list\listtemplateid18\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid1701\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid18}
{\list\listtemplateid19\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid1801\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid19}
{\list\listtemplateid20\listhybrid{\listlevel\levelnfc0\levelnfcn0\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{decimal\}}{\leveltext\leveltemplateid1901\'01\'00;}{\levelnumbers\'01;}\fi-360\li720\lin720 }{\listname ;}\listid20}
{\list\listtemplateid21\listhybrid{\listlevel\levelnfc23\levelnfcn23\leveljc0\leveljcn0\levelfollow0\levelstartat1\levelspace360\levelindent0{\*\levelmarker \{disc\}}{\leveltext\leveltemplateid2001\'01\uc0\u8226 ;}{\levelnumbers;}\fi-360\li720\lin720 }{\listname ;}\listid21}}
{\*\listoverridetable{\listoverride\listid1\listoverridecount0\ls1}{\listoverride\listid2\listoverridecount0\ls2}{\listoverride\listid3\listoverridecount0\ls3}{\listoverride\listid4\listoverridecount0\ls4}{\listoverride\listid5\listoverridecount0\ls5}{\listoverride\listid6\listoverridecount0\ls6}{\listoverride\listid7\listoverridecount0\ls7}{\listoverride\listid8\listoverridecount0\ls8}{\listoverride\listid9\listoverridecount0\ls9}{\listoverride\listid10\listoverridecount0\ls10}{\listoverride\listid11\listoverridecount0\ls11}{\listoverride\listid12\listoverridecount0\ls12}{\listoverride\listid13\listoverridecount0\ls13}{\listoverride\listid14\listoverridecount0\ls14}{\listoverride\listid15\listoverridecount0\ls15}{\listoverride\listid16\listoverridecount0\ls16}{\listoverride\listid17\listoverridecount0\ls17}{\listoverride\listid18\listoverridecount0\ls18}{\listoverride\listid19\listoverridecount0\ls19}{\listoverride\listid20\listoverridecount0\ls20}{\listoverride\listid21\listoverridecount0\ls21}}
\paperw11900\paperh16840\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\qc\partightenfactor0

\f0\b\fs53\fsmilli26667 \cf0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Math project for Data Science
\f1\b0\fs24 \
\pard\pardeftab720\partightenfactor0

\f0\b\fs37\fsmilli18667 \cf0 Group Members:
\f1\b0\fs24 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls1\ilvl0
\f0\b\fs37\fsmilli18667 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Nikita Chistyakov\
\ls1\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Ranjitha Valdivel\
\ls1\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Loic Steve Fohoue Chendjou\
\pard\pardeftab720\partightenfactor0

\f1\b0\fs24 \cf0 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f0\b\fs37\fsmilli18667 \cf0 Topic 2
\f2\b0 :\'a0
\f1\fs24 \

\f0\b\fs37\fsmilli18667 Principle Component Analysis (PCA)
\f1\b0\fs24 \
\

\f0\b\fs37\fsmilli18667 Objective
\f2\b0 :
\f1\fs24 \
\pard\pardeftab720\partightenfactor0

\f2\fs37\fsmilli18667 \cf0 We were interested in exploring this widely used technique that helps to identify patterns in the data by reducing its dimensionality. This concept integrates both machine learning and data analysis. As a method that simplifies the complexity of the data, it transforms long features into a lower dimensional space while retaining most of the information. In other words, it can be explained by a metaphor: summarizing a long book in several pages while keeping the most relevant points.
\f1\fs24 \
\

\f2\fs37\fsmilli18667 PCA is especially useful when dealing with high-dimensional datasets where the number of features is large. It can be used for various applications such as image processing, speech recognition, and data compression.
\f1\fs24 \
\
\pard\pardeftab720\partightenfactor0

\f0\b\fs37\fsmilli18667 \cf0 Our process
\f2\b0 :\'a0
\f1\fs24 \
\pard\pardeftab720\partightenfactor0

\f2\fs37\fsmilli18667 \cf0 The aim of our second project is to perform a PCA in Python using the scikit-learn library; but we have two phases:
\f1\fs24 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls2\ilvl0
\f2\fs37\fsmilli18667 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 First, by using a sample dataset from scikit-learn to see how it works\
\ls2\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 And second, by using a data set downloaded from the Kaggle.com website and we use it to perform the second part of our project\
\pard\pardeftab720\partightenfactor0

\f1\fs24 \cf0 \strokec2 \
\
\
\
\
\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls3\ilvl0
\f2\fs37\fsmilli18667 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Import libraries and load data:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls4\ilvl0
\fs32 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 We are coming across and using the scikit-learn for the first time\
\ls4\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 We have decided on analysing a house-prices dataset from Kaggle\
\pard\pardeftab720\li960\fi960\partightenfactor0
\cf0 {{\NeXTGraphic fm7kzaTPLBB0XZ-6VHe-PH57z0L9cp7vTJfQ-HUfwK5mrtgJO_l3UkYv-UWcMsPzES43RHHEHJkCXqu7-lY8zg2weZ6TgAnkzo8R9Azu7X-zlzIQVL2VUlhF-NXj7zDzSDEGYCphV9huSJZ0iQZO6iU.png \width32000 \height3840 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}\pard\pardeftab720\li960\fi960\partightenfactor0

\f1\fs24 \cf0 \
\pard\pardeftab720\partightenfactor0
\cf0 \strokec2 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls5\ilvl0
\f2\fs37\fsmilli18667 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Standardize data:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls6\ilvl0
\fs32 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 PCA is sensitive to the scale of the input data, so it\'92s important to standardize the data before performing PCA.\'a0\
\ls6\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Data must be in numerical format.\
\ls6\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Standardization involves scaling the data so that it has a mean of 0 and a standard deviation of 1.\
\pard\pardeftab720\partightenfactor0

\f1\fs24 \cf0 \strokec2 \
\pard\pardeftab720\li960\fi960\partightenfactor0

\f2\fs32 \cf0 \strokec2 {{\NeXTGraphic a9gFsKYzNmDN81O9D-lWpQTKS8Fy7SmhLmDTYTOuH7daGA2dvqYX63IV58S6ETeFqqseUiEeISfF86zfF1SxgZ9PU5OQKThkXULLwYA3B3WuQfpndSQ-3WkNCJl-WhhSNqiytOO1k9g6v6JCksjIIwE.png \width6060 \height680 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}\pard\pardeftab720\li960\fi960\partightenfactor0

\f1\fs24 \cf0 \
\pard\pardeftab720\partightenfactor0
\cf0 \strokec2 \
\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls7\ilvl0
\f2\fs37\fsmilli18667 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	3	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Compute covariance matrix:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls8\ilvl0
\fs32 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 The next step is to compute the covariance matrix of the standardized data.\'a0\
\ls8\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 The covariance matrix represents the relationships between the different features in the data.\
\pard\pardeftab720\partightenfactor0

\f1\fs24 \cf0 \strokec2 \
\pard\pardeftab720\li960\fi960\partightenfactor0

\f2\fs32 \cf0 \strokec2 {{\NeXTGraphic JA9r3g_cl1-gJpVqs9ASeehCGyusHshhlwSd9pLqZCfMsmas4UL03baxlM7Txf7yLytLa14A-xRRonDRBSKJV-XbJyx-M6hycw1-UAw4-NW7zgJyPo4QIX7CuRnoFEibVci4skUmS9inixpyZkRN3cg.png \width5340 \height400 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}\pard\pardeftab720\li960\fi960\partightenfactor0

\f1\fs24 \cf0 \
\pard\pardeftab720\partightenfactor0
\cf0 \strokec2 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls9\ilvl0
\f2\fs37\fsmilli18667 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	4	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Compute eigenvectors and eigenvalues of the covariance matrix:\
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls10\ilvl0
\fs32 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 The eigenvectors and eigenvalues of the covariance matrix are used to determine the principal components of the data.\'a0\
\ls10\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 The eigenvectors represent the directions of maximum variance in the data, while the corresponding eigenvalues represent the amount of variance explained by each eigenvector.\
\pard\pardeftab720\partightenfactor0

\f1\fs24 \cf0 \strokec2 \
\pard\pardeftab720\li960\fi960\partightenfactor0

\f2\fs32 \cf0 \strokec2 {{\NeXTGraphic rBlBtK8SVwggGaWWaKWAPyJbevN3Ft19xGradgtuC_gXlvkrVz806pKE5AhYT1PZZo3MOqnG0AgjZJKYeSLWp9cZDGilcAo9PLAGEjD6oHb3go3kKwzLjjhdGJ05EGiIEtIb_HauXqWMLbiktJybosE.png \width9340 \height400 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}\pard\pardeftab720\li960\fi960\partightenfactor0

\f1\fs24 \cf0 \
\pard\pardeftab720\partightenfactor0
\cf0 \strokec2 \
\
\
\pard\pardeftab720\partightenfactor0

\f2\fs37\fsmilli18667 \cf0 V. 	Sorting eigenvalues in descending order:
\f1\fs24 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls11\ilvl0
\f2\fs32 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 We can then select the primary components that account for the most variance in the data. We sort in from highest to lowest so that we can take the highest value for the next step.\
\pard\pardeftab720\partightenfactor0

\f1\fs24 \cf0 \strokec2 \
\pard\pardeftab720\li960\fi960\partightenfactor0

\f2\fs37\fsmilli18667 \cf0 \strokec2 {{\NeXTGraphic FmEW4PxiPdiHKdKLjgglFOsuOioVFAvCXYbU9ZpRN82Gj4ED78qoxW8kf9eOU-c6PnNR9YwZU7xAeIO7wSOkbpXu2MKeVz96g8m328heRoASodMuLy3pcElNNnWmQBXMjDM-WwYcHdtUKwmPaGB-LMc.png \width11020 \height1600 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}\pard\pardeftab720\li960\fi960\partightenfactor0

\f1\fs24 \cf0 \
\pard\pardeftab720\partightenfactor0
\cf0 \strokec2 \
\
\pard\pardeftab720\partightenfactor0

\f2\fs37\fsmilli18667 \cf0 VI. 	Chosing the principal component:
\f1\fs24 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls12\ilvl0
\f2\fs32 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 To accomplish this, we can choose the top k eigenvectors, which are those that match the k biggest eigenvalues.\
\ls12\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 For example, we'll choose k=2 and choose the first two eigenvectors in the sorted eigenvectors list to serve as our primary components.\
\pard\pardeftab720\partightenfactor0

\f1\fs24 \cf0 \strokec2 \
\pard\pardeftab720\li960\fi960\partightenfactor0

\f2\fs32 \cf0 \strokec2 {{\NeXTGraphic 7dxJpeUg--6fvbdcH0uQriDJEMcNi0WzHkL_IHGYjDgU2PDh0e-MgVihZ-8ptCgy7tSz588PlDfAT_IATPBZEVngnGC62-5uI_gRT07QxCrRC9e1lKqHTBW5P-ojOruU-UFRi2leGmJPE63U2A8ok10.png \width11080 \height1620 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}\pard\pardeftab720\li960\fi960\partightenfactor0

\f1\fs24 \cf0 \
\pard\pardeftab720\partightenfactor0
\cf0 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f2\fs37\fsmilli18667 \cf0 VII. 	Project data onto a lower-dimensional linear subspace:\'a0
\f1\fs24 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls13\ilvl0
\f2\fs32 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 In the final step of this stage, the data must be projected onto the principal components-defined lower-dimensional linear subspace.\
\ls13\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 This will transform the data from its original high-dimensional space into a lower-dimensional space while retaining as much of the original information as possible.\
\pard\pardeftab720\partightenfactor0

\f1\fs24 \cf0 \strokec2 \
\pard\pardeftab720\li960\fi960\partightenfactor0

\f2\fs32 \cf0 \strokec2 {{\NeXTGraphic GRdRfSk5vCMEWHyfqpFiHtPZfdBswdxEH2400FP0zQtUSXoEAmpgECzZJZ7e6vN-4a2-gdyP3EZzWvoExE1UbdWcpZbe4FyHt6ecFqYneIdE2Y0W9UOCZJNZzmAbh29WAfoQCCnNCrXuZb6x6XmC9Q.png \width10020 \height1260 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}\pard\pardeftab720\li960\fi960\partightenfactor0

\f1\fs24 \cf0 \
\pard\pardeftab720\partightenfactor0
\cf0 \strokec2 \
\
\pard\pardeftab720\partightenfactor0

\f2\fs37\fsmilli18667 \cf0 VIII. 	Create a PCA object with 2 components:
\f1\fs24 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls14\ilvl0
\f2\fs32 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 This code performs Principal Component Analysis (PCA) on a dataset y and reduces its dimensionality to 2 components using the PCA class from the \'93
\f3 sklearn.decomposition
\f2 \'94 module.\
\ls14\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Once the code is executed, the PCA object will contain the learned PCA model, which can be used to transform new data into lower-dimensional space. The \'93
\f3 y_reduced
\f2 \'94 variable will contain the transformed dataset with only 2 dimensions, which can be used for further analysis or visualization.\
\pard\pardeftab720\partightenfactor0

\f1\fs24 \cf0 \strokec2 \
\pard\pardeftab720\li960\fi960\partightenfactor0

\f2\fs32 \cf0 \strokec2 {{\NeXTGraphic zJ5tdp-aqyJF89607CKVXqrrzVtgghPIoMkvSqSFSEbrILVijfZOH9ujAYUmOzGRfN8bTh_PdjHc_eDmx6cvYwLhzKnOfgdnM5QovC5Q0yBTS2SQRPwsPBRWVj07G3hGVfrnwTYQMlSFEjDAx7uhgA.png \width6600 \height940 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}\pard\pardeftab720\li960\fi960\partightenfactor0

\f1\fs24 \cf0 \
\pard\pardeftab720\partightenfactor0
\cf0 \strokec2 \
\
\pard\pardeftab720\partightenfactor0

\f2\fs37\fsmilli18667 \cf0 IX. 	We can then plot the reduced data using matplotlib:
\f1\fs24 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls15\ilvl0
\f2\fs32 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 This code visualizes the results of the PCA by creating a scatter plot of the transformed dataset 
\f3 y_reduced
\f2  in two dimensions, where the x-axis represents the first principal component and the y-axis represents the second principal component.\
\ls15\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Once the code is executed, a scatter plot will be displayed on the screen showing the transformed dataset 
\f3 y_reduced
\f2  in two dimensions. This plot can be used to gain insights into the structure of the data and to identify patterns or clusters of observations.\
\pard\pardeftab720\partightenfactor0

\f1\fs24 \cf0 \strokec2 \
\pard\pardeftab720\li960\fi960\partightenfactor0

\f2\fs37\fsmilli18667 \cf0 \strokec2 {{\NeXTGraphic VEPnVCpfHB8mBdIbk8Xk7TsebQ5YEyOw7aw2WO5MDXSRDKxfGRrAwatbui1XslVVFlJfWus9A21o4StpUQehgjGtJ_-uAcANZTTLHd_g9lQ4vvuyGTlVcky-0ORv3FvxMT5LPwt8NFaYJ10yBH_5BCo.png \width9540 \height2220 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}\pard\pardeftab720\li960\fi960\partightenfactor0

\f1\fs24 \cf0 \
\pard\pardeftab720\partightenfactor0
\cf0 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f2\fs37\fsmilli18667 \cf0 X. 	Evaluating the results of PCA:
\f1\fs24 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls16\ilvl0
\f2\fs32 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 In order to be sure that Principal Component Analysis (PCA) served its intended function, it is crucial to assess the outcomes.\
\ls16\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Variance explained, cumulative variance explained, and scree plot are just a few from a list of methods for assessing the outcomes of PCA.\
\pard\pardeftab720\partightenfactor0

\f1\fs24 \cf0 \strokec2 \
\pard\pardeftab720\fi960\partightenfactor0

\f2\fs32 \cf0 After performing Principal Component Analysis (PCA), it is important to evaluate the results to ensure that it has achieved its purpose. There are several ways to evaluate the results of PCA, including variance explained, cumulative variance explained, and scree plot.
\f1\fs24 \
\pard\pardeftab720\partightenfactor0
\cf0 \
\pard\pardeftab720\partightenfactor0

\f2\fs37\fsmilli18667 \cf0 XI. 	Fit corresponding variances:
\f1\fs24 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls17\ilvl0
\f2\fs32 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 This method in scikit-learn fits the PCA model to the data\
\pard\pardeftab720\partightenfactor0

\f1\fs24 \cf0 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f2\fs37\fsmilli18667 \cf0 		\strokec2 {{\NeXTGraphic S0YV52o2NPqHhiTmZYhBXpeGW0smzvVO5jfa4qFa7jJLKqcLlqmK9Iwrogz-XZ91o1Os79choCJkyWdtFdjb6IMbHMz8PbDPN_QVnUWzaz9CjTQ1dGnwTCI3U9eLIDJNyNth7ebEEWf-YLjjHKEdtw.png \width3860 \height680 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}
\f1\fs24 \strokec2 \
\

\f2\fs37\fsmilli18667 XII. 	Calculated-variance explained:
\f1\fs24 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls18\ilvl0
\f2\fs32 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 In this code, we are calculating the variance explained by each principal component. The 
\f3 PCA
\f2  object that we created earlier using 
\f3 sklearn.decomposition
\f2  module has a built-in method called 
\f3 explained_variance_ratio_
\f2  which returns an array of the variance explained by each principal component.\
\pard\pardeftab720\partightenfactor0

\f1\fs24 \cf0 \strokec2 \
\pard\pardeftab720\li960\fi960\partightenfactor0

\f2\fs32 \cf0 \strokec2 {{\NeXTGraphic gMk9LbjjPQNtarFsuOsMa553xBeocTphh-KTZgRxpAQDH4VgKIvzObrf34N9j-1UckUjiJZy8fgiYJ1MojmblQy-Globtk92MYnGRCJbkQkbmGkP5ADrGaYOqSV1vHdpbBhpnF3ZAtHy_EJl-72IvA.png \width8000 \height800 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}\pard\pardeftab720\li960\fi960\partightenfactor0

\f1\fs24 \cf0 \
\pard\pardeftab720\partightenfactor0
\cf0 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f2\fs37\fsmilli18667 \cf0 XIII. 	Calculated cumulative-variance explained:
\f1\fs24 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls19\ilvl0
\f2\fs32 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 This is a 1D array or a list of the explained variance ratios of each of the principal components.
\fs37\fsmilli18667 \
\ls19\ilvl0
\fs32 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 The result represents the proportion of the total variance in the original data that can be attributed to that component.\
\pard\pardeftab720\partightenfactor0

\f1\fs24 \cf0 \strokec2 \
\pard\pardeftab720\li960\fi960\partightenfactor0

\f2\fs37\fsmilli18667 \cf0 \strokec2 {{\NeXTGraphic O1-DwmdoZkVtMT-pJm8Db3wzeedNDsgyFL-7FCkdDHzKzx3n-F4OKMkwMF5T6mu8cnVn80xV-epILb-tVJb6cPQWSxs9ReB0VZUgk9Y9zPJZSLQehy8U7TOg9mu7AJehZA7kqxdOgFHVlMh99HQhhQ.png \width6480 \height540 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}\pard\pardeftab720\li960\fi960\partightenfactor0

\f1\fs24 \cf0 \
\pard\pardeftab720\partightenfactor0
\cf0 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f2\fs37\fsmilli18667 \cf0 XIV.	Lastly, a Scree Plot:
\f1\fs24 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls20\ilvl0
\f2\fs32 \cf0 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	1	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 The Scree plot is a graphical representation of the amount of variance explained by each principal component in a Principal Component Analysis (PCA). The plot displays the eigenvalues of each principal component in descending order on the x-axis and the percentage of variance explained by each principal component on the y-axis.\
\ls20\ilvl0\kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	2	}\expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Also used to determine the number of principal components to retain in a dataset. Typically, the eigenvalues decrease rapidly for the first few principal components and then level off. The number of principal components to retain is determined by the "elbow" point in the Scree plot, which represents the point where the eigenvalues start to level off.\
\pard\pardeftab720\partightenfactor0

\f1\fs24 \cf0 \strokec2 \
\pard\pardeftab720\li960\fi960\partightenfactor0

\f2\fs32 \cf0 \strokec2 {{\NeXTGraphic epbX4jHNhDgBboJm51TXjJ4bVNnpuGgTiN58u-EpjZnSNIEFz0bOFZP-8Xe61Nbd2RoRpXe0WqhKQbbpWcS5YhAJbyERcchn6-myEXxlrWFFGLB3GEOvmreWCN29bP192K8G3qbz0K4R60joG8V5rw.png \width16380 \height2280 \appleattachmentpadding0 \appleembedtype0 \appleaqc
}¬}\pard\pardeftab720\li960\fi960\partightenfactor0

\f1\fs24 \cf0 \
\pard\pardeftab720\partightenfactor0
\cf0 \strokec2 \
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\
\pard\pardeftab720\partightenfactor0

\f2\fs32 \cf0 References:
\f1\fs24 \
\pard\tx220\tx720\pardeftab720\li720\fi-720\partightenfactor0
\ls21\ilvl0
\f2\fs32 \cf3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}{\field{\*\fldinst{HYPERLINK "https://pieriantraining.com/machine-learning-in-python-principal-component-analysis-pca/"}}{\fldrslt \expnd0\expndtw0\kerning0
\ul \outl0\strokewidth0 \strokec3 https://pieriantraining.com/machine-learning-in-python-principal-component-analysis-pca/}}\cf0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 \
\ls21\ilvl0\cf3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}{\field{\*\fldinst{HYPERLINK "https://towardsdatascience.com/principal-component-analysis-pca-explained-visually-with-zero-math-1cbf392b9e7d"}}{\fldrslt \expnd0\expndtw0\kerning0
\ul \outl0\strokewidth0 \strokec3 https://towardsdatascience.com/principal-component-analysis-pca-explained-visually-with-zero-math-1cbf392b9e7d}}\cf0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 \
\ls21\ilvl0\cf3 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 {\listtext	\uc0\u8226 	}{\field{\*\fldinst{HYPERLINK "https://www.jcchouinard.com/pca-with-python/"}}{\fldrslt \expnd0\expndtw0\kerning0
\ul \outl0\strokewidth0 \strokec3 https://www.jcchouinard.com/pca-with-python/}}\cf0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 \
\pard\pardeftab720\partightenfactor0

\f1\fs24 \cf0 \strokec2 \
}